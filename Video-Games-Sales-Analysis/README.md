# Video Games Sales Analysis

## Project Overview

Imagine that you worked as a Data Analyst at a video game developer company and your manager want to understand the video game market. Although he has some domain knowledge in gaming industry, he doesnâ€™t know how to manipulate the data. Therefore, he asked me to create an easily used interactive dashboard.

My manager want to know the following information on the dashboard:

1. Top 5 Sales by Platform
2. Top 5 Sales by Genre
3. Top 5 Sales by Publisher
4. Total Sales (in millions) & Total Sales (% in Global) 

The user can choose a specific **region** and **year** so that the data and graphs in the dashboard would be altered correspondingly. Other than these four question listed above I'll create another three graphics on the dashboard that remain static regardless of the specific region and year:

1. Yearly Total Sales for all of the Region: Using stacked area chart to represent each region for each stack
2. Sales Percentage by Region: Pie/Donut chart where each piece of 'donut' represent the region
3. Genre Trend by Decade: Create a pivot table chart where the row is genre, the column is the decade, the value is the percentage of the sales by genre on that particular decade.

## Dataset

This dataset contains a list of video games with sales greater than 100,000 copies. It was generated by a scrape of vgchartz.com. You can access the dataset source [here](https://www.kaggle.com/gregorut/videogamesales) or the [vgsales.csv](vgsales.csv) on this repo.

## Data Cleaning

Before we continue analyzing and create the dashboard, we have to clean the data first so that we can produce accurate analysis. 

For the data cleaning part, I'm doing the data cleaning part using python code. The complete step by step of the data cleaning can be access in this repo on the [data_cleaning.ipynb](data_cleaning.ipynb) file, but I'll explain the big picture of the data cleaning process here.

### Read the dataset

Code:
```python
import pandas as pd
df = pd.read_csv("vgsales.csv")
print(f"The dataset has {df.shape[0]} rows and {df.shape[1]} columns.")
```
Result:
```
The dataset has 16598 rows and 11 columns.
```

### Check for missing value

Code:
```python
df.isna().sum()
```
Results:
```
Rank              0
Name              0
Platform          0
Year            271
Genre             0
Publisher        58
NA_Sales          0
EU_Sales          0
JP_Sales          0
Other_Sales       0
Global_Sales      0
```

271 missing values on `Year` column and 58 missing values on `Publisher` columns is retalively small compared to the number of rows (16598) so we can just drop the row that contain missing values. Let's drop it using `dropna()` method.

```python
df.dropna(subset=["Year", "Publisher"], axis=0, inplace=True)
```

### Check for Year Range

The dataset should contain games that release from 1980 until 2016. So we have to make sure the `Year` column is in the range (1980 - 2016).

Code:
```python
print(sorted(df["Year"].unique()))
```
Results:
```
[1980.0, 1981.0, 1982.0, 1983.0, 1984.0, 1985.0, 1986.0, 1987.0, 1988.0, 1989.0, 1990.0, 1991.0, 1992.0, 1993.0, 1994.0, 1995.0, 1996.0, 1997.0, 1998.0, 1999.0, 2000.0, 2001.0, 2002.0, 2003.0, 2004.0, 2005.0, 2006.0, 2007.0, 2008.0, 2009.0, 2010.0, 2011.0, 2012.0, 2013.0, 2014.0, 2015.0, 2016.0, 2017.0, 2020.0]
```

Year 2017 and 2020 shouldn't be in the dataset. Let's remove it using `isin()` where it filter rows that contain year 2017 and 2020.

```python
df = df[~df.Year.isin([2017, 2020])]
```

### Write the cleaned data back to CSV file


Now that the dataset are cleaned, it's time to write the dataset back into CSV file and analyze it further.

```python
df.to_csv("vgsales_cleaned.csv", index=False)
```

## Creating the Dashboard

The [vgsales_cleaned.csv](vgsales_cleaned.csv) are the dataset that we are using to create the dashboard. You can access the full dashboard on this [link](https://docs.google.com/spreadsheets/d/1v1mzEqdfkri8pFXqiyR0Bq96LubRfP7DgBMaQVhPDR8/edit#gid=1497578976).
